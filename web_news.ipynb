{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#from flask import Flask\n",
    "import sqlite3\n",
    "\n",
    "#import os\n",
    "import urllib\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup,NavigableString\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "link=[]\n",
    "text=[]\n",
    "title=[]\n",
    "count=[]\n",
    "real=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Zerodha.com\n",
    "def zerodha():\n",
    "    r = urllib.request.urlopen('http://pulse.zerodha.com/').read()\n",
    "    soup = BeautifulSoup(r,\"html5lib\")\n",
    "    soup.prettify()\n",
    "    for i in soup:\n",
    "        for j in i.find_all('h2',class_='title'):\n",
    "            text.append(j.find('a').get_text().strip())\n",
    "            link.append(j.find('a').get('href'))\n",
    "            real.append('Business')\n",
    "    \n",
    "        for j in i.find_all('div',class_=\"desc\"):\n",
    "            for k in j.find_next_siblings(\"span\",class_=\"feed\"):\n",
    "                title.append(k.get_text().strip())\n",
    "            \n",
    "zerodha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#HindustanTimes\n",
    "def hindustantimes():\n",
    "    r = urllib.request.urlopen('http://www.hindustantimes.com/').read()\n",
    "    soup1 = BeautifulSoup(r,\"html5lib\")\n",
    "    soup1.prettify()\n",
    "    for i in soup1.find_all('div',class_=\"media-heading headingfour\"):\n",
    "        text.append(i.find('a').text.strip())\n",
    "        link.append(i.find('a').get('href')) \n",
    "        title.append('-The Hindustan Times')\n",
    "        real.append('')\n",
    "        \n",
    "    for i in soup1.find_all('div',class_=\"random-tx clearfix\"):\n",
    "        for j in i.find_all('div',class_=\"para-txt\"):\n",
    "            text.append(j.find('a').text.strip())\n",
    "            link.append(j.find('a').get('href'))\n",
    "            title.append('-The Hindustan Times')\n",
    "            real.append('')\n",
    "        \n",
    "    #extractging news related to lifestyle\n",
    "    r = urllib.request.urlopen('http://www.hindustantimes.com/lifestyle/').read()\n",
    "    soup1 = BeautifulSoup(r,\"html5lib\")\n",
    "    soup1.prettify()\n",
    "    for i in soup1.find_all('div',class_=\"media-heading headingfour\"):\n",
    "        text.append(i.find('a').text.strip())\n",
    "        link.append(i.find('a').get('href'))\n",
    "        title.append('-The Hindustan Times')\n",
    "        real.append('lifestyle')\n",
    "        \n",
    "    for i in soup1.find_all('div',class_=\"random-tx clearfix\"):\n",
    "        for j in i.find_all('div',class_=\"para-txt\"):\n",
    "            text.append(j.find('a').text.strip())\n",
    "            link.append(j.find('a').get('href'))\n",
    "            title.append('-The Hindustan Times') \n",
    "            real.append('lifestyle')\n",
    "\n",
    "    #extracting technology related news        \n",
    "    r = urllib.request.urlopen('http://www.hindustantimes.com/tech/').read()\n",
    "    soup1 = BeautifulSoup(r,\"html5lib\")\n",
    "    soup1.prettify()\n",
    "    for i in soup1.find_all('div',class_=\"media-heading headingfour\"):\n",
    "        text.append(i.find('a').text.strip())\n",
    "        link.append(i.find('a').get('href'))\n",
    "        title.append('-The Hindustan Times')\n",
    "        real.append('Technology')\n",
    "        \n",
    "    for i in soup1.find_all('div',class_=\"random-tx clearfix\"):\n",
    "        for j in i.find_all('div',class_=\"para-txt\"):\n",
    "            text.append(j.find('a').text.strip())\n",
    "            link.append(j.find('a').get('href'))\n",
    "            title.append('-The Hindustan Times') \n",
    "            real.append('Technology')\n",
    "    \n",
    "    \n",
    "    #extracting entertainment related news\n",
    "    r = urllib.request.urlopen('http://www.hindustantimes.com/entertainment/').read()\n",
    "    soup1 = BeautifulSoup(r,\"html5lib\")\n",
    "    soup1.prettify()\n",
    "    for i in soup1.find_all('div',class_=\"media-heading headingfour\"):\n",
    "        text.append(i.find('a').text.strip())  \n",
    "        link.append(i.find('a').get('href'))\n",
    "        title.append('-The Hindustan Times')\n",
    "        real.append('Entertainment')\n",
    "        \n",
    "    for i in soup1.find_all('div',class_=\"random-tx clearfix\"):\n",
    "        for j in i.find_all('div',class_=\"para-txt\"):\n",
    "            text.append(j.find('a').text.strip())\n",
    "            link.append(j.find('a').get('href'))\n",
    "            title.append('-The Hindustan Times')   \n",
    "            real.append('Entertainment')\n",
    "        \n",
    "        \n",
    "\n",
    "hindustantimes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#The Times OF India\n",
    "def times():\n",
    "    #extracting environment related news\n",
    "    r = urllib.request.urlopen('http://timesofindia.indiatimes.com/home/environment').read()\n",
    "    soup2 = BeautifulSoup(r,\"html5lib\")\n",
    "    soup2.prettify()\n",
    "    for i in soup2.find_all('div',id=\"fsts\"):\n",
    "        for j in i.find_all('h2'):\n",
    "            text.append(j.find('a').text.strip())\n",
    "            link.append('http://timesofindia.indiatimes.com'+j.find('a').get('href'))\n",
    "            title.append('-The Times of India')\n",
    "            real.append('Environment')\n",
    "    #extracting fitness news\n",
    "    r = urllib.request.urlopen('http://timesofindia.indiatimes.com/life-style/health-fitness/fitness').read()\n",
    "    soup2 = BeautifulSoup(r,\"html5lib\")\n",
    "    soup2.prettify()\n",
    "    for i in soup2.find_all('h3',class_=\"hl_h3\"):\n",
    "        text.append(j.find('a').text.strip())\n",
    "        link.append('http://timesofindia.indiatimes.com'+j.find('a').get('href'))\n",
    "        title.append('-The Times of India')\n",
    "        real.append('lifestyle')\n",
    "        \n",
    "times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def indiatoday():\n",
    "    #Extracting enviroment related news\n",
    "    r = urllib.request.urlopen('http://indiatoday.intoday.in/section/76/1/environment.html').read()\n",
    "    soup = BeautifulSoup(r,\"html5lib\")\n",
    "    soup.prettify()\n",
    "    for i in soup.find_all('div',class_=\"innerbox\"):\n",
    "        text.append(i.find('a').text.strip())\n",
    "        link.append(i.find('a').get('href'))\n",
    "        title.append('-India Today')\n",
    "        real.append('Environment')\n",
    "        \n",
    "indiatoday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from news_classifier import predict_news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cat=[]\n",
    "count=[]\n",
    "time=[]\n",
    "for i in range(len(link)):\n",
    "    temp=[text[i]]\n",
    "    cat.append(predict_news(temp))\n",
    "    count.append(i+1)\n",
    "    time.append(datetime.date.today())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# from sqlalchemy import Column,ForeignKey,Integer,String\n",
    "# from sqlalchemy.ext.declarative import declarative_base\n",
    "# from sqlalchemy.orm import relationship,sessionmaker\n",
    "# from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# Base = declarative_base()\n",
    "\n",
    "# class Alldata(Base):\n",
    "#     __tablename__='all_data'\n",
    "#     headline = Column(String(200),nullable=False)\n",
    "#     source = Column(String(30), nullable=False)\n",
    "#     url = Column( String(300))\n",
    "#     category = Column(String(30),nullable=False)\n",
    "#     key = Column(Integer,primary_key=True)\n",
    "#     uploaded = Column(DateTime,, default=datetime.date.today())\n",
    "    \n",
    "\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "from database_setup import Base,Alldata\n",
    "\n",
    "\n",
    "engine = create_engine('sqlite:///newsdata.db')\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "DBSession = sessionmaker(bind = engine)\n",
    "session = DBSession()\n",
    "for i in range(len(link)):\n",
    "    temp = Alldata(headline=text[i] , source=title[i] ,url =link[i] , category =cat[i] ,key=count[i],uploaded=time[i],actual=real[i])\n",
    "    session.add(temp)\n",
    "    session.commit()\n",
    "    \n",
    "    \n",
    "link=[]\n",
    "text=[]\n",
    "title=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "#making server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
